---
layout: post
title: '解决高并发读写的想法(纯文字)'
subtitle: '如何配合redis来解决高并发请求写库'
date: 2020-06-11
categories: 技术
tags: django redis
image: /assets/img/blog/redis-black.png



---

我们遇见的商城秒杀系统 都可以兼容高并发  就想实现高并发这么一个操作。

这样避免了爬虫的疯狂请求，也兼容了多用户同时操作

但在遇到高并发时候，orm对数据库操作会成为悲观锁，无论多少次请求，orm都会把数据库锁死不能更改。

而使用mysql直连操作的话，同一时间过高的连接修改，会报错出数据库被过多连接从而崩掉。

这就是所谓的数据库崩溃，高并发的请求的数据库读写会让数据不稳定。

<br/>

有一个想法：
如果遇到mysql，oracle等大型数据库高密集读写的时候，先把需要更改的数据放进redis。

高并发高请求的时候只对redis进行操作。只通过redis记录更改的值

等到最后的时候 在把redis中的数据取出来，与数据库进行同步

在或者把同步数据逻辑封装成一个异步任务，使用异步队列的定时执行。

也可以定时对数据库进行同步操作

这样的话数据库本身的读写次数非常少，对性能还有了一个极高的优化，

把所有的高请求读写叫给redis来进行，redis简称工具人  数据先给redis进行操作

最后还是要同步回主数据库 用别人的鸡 给自己生蛋  反正这个redis(鸡)也用不坏

有了redis 这么一个高性能读写的数据库 可帮助了大忙

要不然对更改数据的orm进行上锁，或者更改mysql的最大连接上限才能解决这个高并发数据库读写的问题



